# -*- coding: utf-8 -*-
"""precipitation nowcasting__CleanedGRIB_s3Concat

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c1m4y0AAMBpSks1B1LZPWDiMAcxheh76
"""

#!pip -q install tensorflow~=2.5.0 numpy~=1.19.5 matplotlib~=3.2.2 tensorflow_hub~=0.12.0 cartopy~=0.19.0
#!pip install pyproj
#!pip install boto3
#!pip install botocore 
#!pip uninstall -y shapely
#!pip install shapely --no-binary shapely

"""## Imports:"""

import datetime
import os
#import cartopy

import matplotlib
import matplotlib.pyplot as plt
from matplotlib import animation
import numpy as np
#import shapely.geometry as sgeom
import tensorflow as tf 

import matplotlib.colors as mcolors
#from pyproj import Proj

import boto3 
from botocore import UNSIGNED
from botocore.config import Config
import matplotlib.patches as mpatches
import io
import os
import gc
import json

from mrms_nowcasting import MRMSNowCastingFunctions

waterloo_specBounds = [-82.2, -79.35576, 42.7, 44.603355]
map_extent_crop = [-86.0, -78.05576, 39.0, 47.603355] 
w_specextent = [-83.2, -78.35576, 41.5, 45.603355]

gribGroundTruthsPath = "examples/predictions/mrms_24hr/"
TFRecordPath = "test-predictions/mrms_24hr/"

"""## Dataset location"""

TFHUB_BASE_PATH = "gs://dm-nowcasting-example-data/tfhub_snapshots"

"""Use this to authenticate as required for access to GCS buckets:

## Dataset reader code
"""

fn = MRMSNowCastingFunctions()

def generate_rainfall(pred_arr):
    top_y = 138 # specific starting point vals in goes crop
    left_x = 106
    px_offset = 32 # size of how large of area to analyze
    rainfall = {}
    for frame in range(pred_arr.shape[0]):
        rain_frame = pred_arr[frame, top_y:top_y + px_offset, left_x:left_x + px_offset, 0]
        avg_rain_intensity = np.mean(rain_frame)
        rain_cover = rain_frame[rain_frame > 0.1].shape[0] / (px_offset * px_offset)
        print("There is a ", rain_cover * (0.89 - (frame*0.01)), " percent chance of ", avg_rain_intensity, " mm of rain")
        rainfall[frame] = {'img_index': frame, 'percentage': str(rain_cover * (0.89 - (frame*0.01)) ) ,'rain_intensity':int(avg_rain_intensity)}  

    return rainfall

def GribReadAndPredict(TFRecordPath,gribGroundTruthsPath,basePath,numberFiles):
  filenames = fn.getS3FileNames(TFRecordPath,basePath,numberFiles)
  print(filenames)
  print(len(filenames))
  if( len(filenames) < 4):
    print('not enough files')
    return False

  s3_client = boto3.client( 's3',
            aws_access_key_id="AKIAWRHKEEZVRHAQDW6L",
            aws_secret_access_key="JF3BJEi1FcBwEBaisIK5FAIOV9NzF83yEMEzQQoh",
            region_name="us-east-1"
        )
  #s3://lumo-app/examples/predictions/mrms_24hr/  
  response = s3_client.list_objects_v2(Bucket="lumo-app", Prefix=gribGroundTruthsPath) #Prefix="test-predictions/mrms_grib/")
  if 'Contents' in response:
      for object in response['Contents']:
          print('Deleting', object['Key'])
          s3_client.delete_object(Bucket="lumo-app", Key=object['Key'])

  radar_frames = np.empty((0,256,256,1))
  #big_radar_frames = np.empty((0,3500, 7000,1))
  FrameRelatedData = []
  #concat 4
  filenames = filenames[0:4] # confirm only 4
  data = fn.get_dataset(filenames) 
  grib_data = next(iter( data )) #gribdata.copy() #next(iter(  ))

  #print('test') 
  for i,fileName in enumerate(filenames):
    print(fileName) 
    tmp = grib_data#.copy() 
    #print('radar check')
    #print(i)
    #print(tmp['radar_frames'][i])
    #print(tmp['radar_frames'][i].numpy())
    #test =  {} 
    #tmp['radar_frames'] = fn.rescale_linear(tmp['radar_frames'].numpy(), 0, 20)
    #test['radar_frames'] = tmp['radar_frames'][i][1000:1256, 4844:5100] #rescale_linear(tmp['radar_frames'][i][1000:1256, 4844:5100].numpy(), 0, 20) #tmp['radar_frames'][i][1000:1256, 4844:5100]
    #test['longitude'] = tmp['longitude'][i][4844:5100]
    #test['latitude'] = tmp['latitude'][i][1000:1256]
    #fn.graphGrib(test,waterloo_specBounds)#map_extent_crop)
    #graphGrib(test)#map_extent_crop) 
    radar_frames = np.append(radar_frames, np.expand_dims(np.expand_dims(tmp['radar_frames'][i][1000:1256, 4844:5100], axis=2), axis=0) , axis=0) 
    FrameRelatedData.append( (grib_data['end_time_timestamp'],fn.plotBounds(tmp['longitude'][i][4844:5100] - 360 , tmp['latitude'][i][1000:1256]))  )
  
  print('start prediction')
  module = fn.load_module(256, 256)
  print(f"frames shape: {radar_frames.shape}")
  num_samples = 1 
  samples = fn.predict(module, tf.cast(radar_frames, tf.float32),
                    num_samples=num_samples, include_input_frames_in_result=False)
  
  print('gen rainfall ')
  rainfall = generate_rainfall(samples[0][::2])
  
  with open( basePath+"/data_24.csv", "w") as f:
      for key in rainfall.keys():
          f.write( "%s,%s\n"%(key,rainfall[key]) )

  session = boto3.Session(
                aws_access_key_id="AKIAWRHKEEZVRHAQDW6L",
                aws_secret_access_key="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",
            )
  s3 = session.resource('s3')

  bucket = s3.Bucket("lumo-app")

  #datetime_str = datetime.datetime.utcfromtimestamp(FrameData[0][3]).strftime("%Y-%m-%d-%H%M")
  #print(datetime_str)
  #index_str = f'0{str(i)}' if i < 10 else str(i)
            
  #index = "{:02d}".format(i)

  print(rainfall)
  print("upload rainfall data")

  bucket.put_object(Body=json.dumps(rainfall), ContentType="application/json", Key= gribGroundTruthsPath + "rainFallData")

  fn.plot_animation_grib(samples[0][::2],gribGroundTruthsPath,FrameRelatedData[3],waterloo_specBounds,vmin=0, vmax=20, cmap="jet")
  gc.collect()

  return True
'''
gribGroundTruthsPath = "examples/predictions/mrms_1hr/"#mrms_24hr/"
TFRecordPath = "test-predictions/mrms_1hr/"#24hr/"
basePath = "./data_1hr/"

GribReadAndPredict(TFRecordPath,gribGroundTruthsPath,basePath,13)
'''
